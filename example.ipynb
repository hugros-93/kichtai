{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kichtAI: \n",
    "### Example for rap corpus creation, model training and text generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow import TensorShape\n",
    "\n",
    "from kichtai.genius import GeniusParser\n",
    "from kichtai.corpus import RapCorpus\n",
    "from kichtai.nn import rnn_seq_loss, get_rnn_seq_model, plot_history, talk_from_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rap corpus creation using Genius API\n",
    "##### Reference: https://dev.to/willamesoares/how-to-integrate-spotify-and-genius-api-to-easily-crawl-song-lyrics-with-python-4o62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your Genius token, stored in a 'token.txt' file, and test its validity\n",
    "token = open('token.txt', 'r').read()\n",
    "rap_parser = GeniusParser(token)\n",
    "rap_parser.test_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize artists dict.\n",
    "list_artists = ['Booba']\n",
    "rap_parser.create_dict_artists(list_artists=list_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for songs of artists in 'list_artists'\n",
    "rap_parser.search_for_songs(nb_page=1, per_page=3)\n",
    "rap_parser.dict_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for raw lyrics\n",
    "rap_parser.search_for_lyrics()\n",
    "rap_parser.dict_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final corpus by concatenation and cleaning of lyrics \n",
    "corpus = RapCorpus(rap_parser.dict_artists)\n",
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate and clean corpus\n",
    "corpus.create_corpus()\n",
    "corpus.clean_text()\n",
    "corpus.print_text(limit=500, random_select=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top words in corpus\n",
    "corpus.plot_dictionary(top=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot vocabulary of the corpus\n",
    "corpus.plot_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a text generation model using RNN\n",
    "##### Refrence: https://www.tensorflow.org/tutorials/text/text_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "len_seq = 64\n",
    "embedding_dim = 8\n",
    "rnn_units = 8\n",
    "batch_size = 64\n",
    "\n",
    "epochs = 1000\n",
    "patience = 10\n",
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text\n",
    "text = corpus.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Mapping\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "# Data\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in range(len(text)-len_seq-1):\n",
    "    X.append(text[i:i+len_seq])\n",
    "    Y.append(text[i+1:i+len_seq+1])\n",
    "    \n",
    "data = np.array([[char2idx[i] for i in x] for x in X])\n",
    "targets = np.array([[char2idx[i] for i in y] for y in Y])\n",
    "\n",
    "data, targets = shuffle(data, targets, random_state=random_state)\n",
    "print(f\"Data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "TRAIN_BUF = int(data.shape[0]*0.8) - (int(data.shape[0]*0.8) % batch_size)\n",
    "TEST_BUF = int(data.shape[0]*0.2) - (int(data.shape[0]*0.2) % batch_size)\n",
    "\n",
    "data_train = data[:TRAIN_BUF]\n",
    "data_validation = data[TRAIN_BUF:TRAIN_BUF+TEST_BUF]\n",
    "targets_train = targets[:TRAIN_BUF]\n",
    "targets_validation = targets[TRAIN_BUF:TRAIN_BUF+TEST_BUF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tf model\n",
    "model = get_rnn_seq_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "name=f'sequence_model_{len_seq}_{embedding_dim}_{rnn_units}_{batch_size}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks and compil\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience)\n",
    "mc = ModelCheckpoint(f'outputs/{name}.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "optimizer = Adam(learning_rate=lr)\n",
    "model.compile(optimizer=optimizer, loss=rnn_seq_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "history = model.fit(data_train, targets_train, \n",
    "              validation_data = (data_validation, targets_validation), \n",
    "              epochs=epochs, \n",
    "              batch_size=batch_size, \n",
    "              verbose=0,\n",
    "              callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot history\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate lyrics from initial text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load final model for generation\n",
    "model = get_rnn_seq_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "name=f'sequence_model_{len_seq}_{embedding_dim}_{rnn_units}_{batch_size}'\n",
    "model.load_weights(f'outputs/{name}.h5')\n",
    "model.build(TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = \"personne personne\"\n",
    "nb_steps = 500\n",
    "temperature = 0.5\n",
    "\n",
    "text_predict = talk_from_text(text_input, model, char2idx, idx2char, len_seq, nb_steps=nb_steps, temperature=temperature)\n",
    "\n",
    "print(f\"{text_input}...\\n...{text_predict[len(text_input):]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}